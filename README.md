# License

The source code is distributed under the MIT license. See LICENSE.md for more information.

# Table of Contents

[TOC]

# App name

[APPNAME] is a chatroom in which you can communicate with body language, specifically made for Eric.

## About Eric

Eric is my tester and he is the one I'll be creating this application for. Eric wants to have an application in which he can communicates with body language in a chat. He has a motoric disability. He's in a wheelchair and has difficulties raising his arms and fine movements with his fingers. It was my duty to create an app for him according to his preferences and how he controls the application.

This was the user scenario I based my app on:

[USERSCENARIO]

## Functionalities

This is project's whishlist of its functionalities:

- [] You are able to communicate body langauge in a chat

## How do you use the application?

[APPNAME] is a chat that Eric can use and communicate body language with.

## Live Demo

To use the app, you can use the following demo: [LINK]

## Installation

To install the app locally on your computer, you can follow these next steps:

1. Clone this repository into a folder of your choice on your local machine.
2. Open the project in your code editor.
3. Open the terminal in your code editor.
4. Install the dependencies by typing `npm i` in the terminal.
5. Run the application by typing `npm run dev` in the terminal.
6. Go to `localhost:8000` in the browser and enjoy the app!

# Process

In this section I'll be talking more about my process:

## Body Language

The only information we got was that Eric wants to have a chat in which he can communicate bodylanguage. To give myself inspiration, I looked up what different forms of communication are considered body language:

- Facial expressions
- Gestures (hand or arm movements, waving or shrugging)
- Posture
- Eye contact
- Tone of voice
- Touch
- Proximity (how close we stand can communicate intimacy, discomfort or dominance)
- Micro-expressions (brief, fleeting expressions that reveal our true emotions, often unconsciously)

## Ideas

I had a few ideas for this project before we could speak to our tester:

1. Create an avatar in the chatroom that can mimic the expression on the user's face. The user can use a camera or manually choose which expression to show. The avatar is able to make eye-contact with the user on the receiving end, but also with the user itself. These expressions will be measured by an AI.

If Eric doesn't likes it that his face is being tracked and wants to choose the body language manually, then I'll need a platform with small buttons which he actually can use, or try out the keyboard. If both of these won't work I can try the touchscreen of my laptop or use the trackpad. I can also try a drawing.

If Eric is unable to use the keyboard and all it's functions, then I might want to implement speech-to-text.

If Eric is unable to use the mouse but able to use the keyboard, I'll make sure the app is fully functional with keyboard.

If Eric is unable to use a laptop keyboard, I'll try a regular keyboard with deeper keys.

If Eric has difficulties using a laptop, I'll try to maybe look for a smaller kind of keyboard, he'll be able to use.
